import cv2
import numpy as np
import time
import math

class Team250PiggyVision:
    # ###################################################################################################
    ## Constructor
    
    def __init__(self):

        self.__blur_radius = 4.504504504504505

        self.blur_output = None

        self.__cv_extractchannel_src = self.blur_output
        self.__cv_extractchannel_channel = 1.0

        self.cv_extractchannel_output = None

        self.__cv_threshold_src = self.cv_extractchannel_output
        self.__cv_threshold_thresh = 30.0
        self.__cv_threshold_maxval = 255.0
        self.__cv_threshold_type = cv2.THRESH_BINARY

        self.cv_threshold_output = None

        self.__mask_input = self.blur_output
        self.__mask_mask = self.cv_threshold_output

        self.mask_output = None

        self.__normalize_input = self.mask_output
        self.__normalize_type = cv2.NORM_MINMAX
        self.__normalize_alpha = 0.0
        self.__normalize_beta = 255.0

        self.normalize_output = None

        self.__hsv_threshold_input = self.normalize_output
        self.__hsv_threshold_hue = [0.0, 49.07338796517677]
        self.__hsv_threshold_saturation = [0.0, 0.454545996405874]
        self.__hsv_threshold_value = [41.276978417266186, 255.0]

        self.hsv_threshold_output = None

        self.__cv_erode_src = self.hsv_threshold_output
        self.__cv_erode_kernel = None
        self.__cv_erode_anchor = (-1, -1)
        self.__cv_erode_iterations = 2.0
        self.__cv_erode_bordertype = cv2.BORDER_CONSTANT
        self.__cv_erode_bordervalue = (-1)

        self.cv_erode_output = None

        self.__cv_dilate_src = self.cv_erode_output
        self.__cv_dilate_kernel = None
        self.__cv_dilate_anchor = (-1, -1)
        self.__cv_dilate_iterations = 1.0
        self.__cv_dilate_bordertype = cv2.BORDER_CONSTANT
        self.__cv_dilate_bordervalue = (-1)

        self.cv_dilate_output = None

        self.__find_contours_input = self.cv_dilate_output
        self.__find_contours_external_only = False

        self.find_contours_output = None

        self.__filter_contours_contours = self.find_contours_output
        self.__filter_contours_min_area = 25.0
        self.__filter_contours_min_perimeter = 0.0
        self.__filter_contours_min_width = 0.0
        self.__filter_contours_max_width = 1000.0
        self.__filter_contours_min_height = 0.0
        self.__filter_contours_max_height = 1000.0
        self.__filter_contours_solidity = [0, 100]
        self.__filter_contours_max_vertices = 1000000.0
        self.__filter_contours_min_vertices = 0.0
        self.__filter_contours_min_ratio = .3
        self.__filter_contours_max_ratio = .7

        self.filter_contours_output = None

    # ###################################################################################################
    ## Process function with no USB output
    def processNoUSB(self, inframe):
        headless = True
        
    # Constantly look and acquire color camera images 

        source0 = inimg = imread('../images/IMG_6339.JPG')
        outimg = inimg 
        imshow('outimg', outimg)
        cv.waitKey(500)
        # Start measuring image processing time (NOTE: does not account for input conversion time):

        ## BEGIN GRIP CODE

        # Runs the OpenCV pipeline and sets all outputs to new values.

        self.__blur_input = source0
        (self.blur_output) = self.__blur(self.__blur_input, "Gaussian_Blur", self.__blur_radius)

        # Step CV_extractChannel0:
        self.__cv_extractchannel_src = self.blur_output
        (self.cv_extractchannel_output) = self.__cv_extractchannel(self.__cv_extractchannel_src, self.__cv_extractchannel_channel)

        # Step CV_Threshold0:
        self.__cv_threshold_src = self.cv_extractchannel_output
        (self.cv_threshold_output) = self.__cv_threshold(self.__cv_threshold_src, self.__cv_threshold_thresh, self.__cv_threshold_maxval, self.__cv_threshold_type)

        # Step Mask0:
        self.__mask_input = self.blur_output
        self.__mask_mask = self.cv_threshold_output
        (self.mask_output) = self.__mask(self.__mask_input, self.__mask_mask)

        # Step Normalize0:
        self.__normalize_input = self.mask_output
        (self.normalize_output) = self.__normalize(self.__normalize_input, self.__normalize_type, self.__normalize_alpha, self.__normalize_beta)

        # Step HSV_Threshold0:
        self.__hsv_threshold_input = self.normalize_output
        (self.hsv_threshold_output) = self.__hsv_threshold(self.__hsv_threshold_input, self.__hsv_threshold_hue, self.__hsv_threshold_saturation, self.__hsv_threshold_value)

        # Step CV_erode0:
        self.__cv_erode_src = self.hsv_threshold_output
        (self.cv_erode_output) = self.__cv_erode(self.__cv_erode_src, self.__cv_erode_kernel, self.__cv_erode_anchor, self.__cv_erode_iterations, self.__cv_erode_bordertype, self.__cv_erode_bordervalue)

        # Step CV_dilate0:
        self.__cv_dilate_src = self.cv_erode_output
        (self.cv_dilate_output) = self.__cv_dilate(self.__cv_dilate_src, self.__cv_dilate_kernel, self.__cv_dilate_anchor, self.__cv_dilate_iterations, self.__cv_dilate_bordertype, self.__cv_dilate_bordervalue)

        # Step Find_Contours0:
        self.__find_contours_input = self.cv_dilate_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)

        # Step Filter_Contours0:
        self.__filter_contours_contours = self.find_contours_output
        (self.filter_contours_output) = self.__filter_contours(self.__filter_contours_contours, self.__filter_contours_min_area, self.__filter_contours_min_perimeter, self.__filter_contours_min_width, self.__filter_contours_max_width, self.__filter_contours_min_height, self.__filter_contours_max_height, self.__filter_contours_solidity, self.__filter_contours_max_vertices, self.__filter_contours_min_vertices, self.__filter_contours_min_ratio, self.__filter_contours_max_ratio)

        ### End Grip Code
       
        ### Start Non-Grip Common/Default Code

        def sort_contours(cnts, method = "left-to-right"):
            
            reverse = False
            i=0
        
            if method == "right-to-left" or method == "bottom-to-top":
                reverse = True
            
            if method == "top-to-bottom" or method == "bottom-to-top":
                i=i
            
            boundingBoxes = [cv2.boundingRect(c) for c in cnts]
            (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),key=lambda b:b[1][i], reverse=reverse))
        
            return (cnts, boundingBoxes)    

        def draw_contour(image, c, i):
            M = cv2.moments(c)
            cX = int(M["m10"]/M["m00"])
            cY = int(M["m01"]/M["m00"])
        
            cv2.putText(image, "#{}".format(i+1),(cX-20,cY),font, font_size, (255,255,255), 2)
        
            return image
             
        ### Start Additional Non-Grip Custom Code
          
        # Constants and Variables
        font = 0
        font_size = .4      
        degrees_to_target = 0
        w, h = 2, 2;
        contour_keeper = [[0 for x in range(w)] for y in range(h)] 
        tape_keeper = [] 
        cx = 0
        cy = 0
        closest_dock = -99.99

        # Draws all contours on original image in red
        cv2.drawContours(outimg, self.filter_contours_output, -1, (0, 0, 250), 1)
        
        # Gets number of contours
        NumOfContours = len(self.filter_contours_output)
        if headless == False: cv2.putText(outimg, "Contours Found: " + str(NumOfContours), (3, 450), font, font_size, (255,255,255), 1, cv2.LINE_AA)
        
        # Sorts contours from left to right
        #newContours = sortByArea(self.filter_contours_output)  # Sorts contours by area
        newContours = sorted(self.filter_contours_output, key=lambda ctr: cv2.boundingRect(ctr)[0])
                               
        #Organize the contours we found
        if NumOfContours != 0:                   # If there are things to analyze in the image...
            for i in range (NumOfContours):      # Loop through everything found...
                cnt = newContours[i]
                
                rect = cv2.minAreaRect(cnt)
                
                box = cv2.boxPoints(rect)
                box = np.int0(box)
                x,y,theta = cv2.minAreaRect(cnt)

                cv2.drawContours(outimg,[box],0,(0,255,0),2)
                if headless == False: cv2.putText(outimg, "C" + str(i) + " at " + str(round(theta)) + "'", (round(x[0]-10),round(x[1]-40)), font, font_size, (255,255,255), 1, cv2.LINE_AA)

                cnt_area = cv2.contourArea(cnt)
                hull = cv2.convexHull(cnt)
                hull_area = cv2.contourArea(hull)
                p = cv2.approxPolyDP(hull, -1, 1)
        
                # Determine if something is a piece of tape correctly angled or not
                if (theta > -25 and theta < -8) and theta != 0.0:
                    tape_keeper.insert(i,[x,y,"L"])
                elif (theta > -86 and theta < -68) and theta != 0.0:
                    tape_keeper.insert(i,[x,y,"R"])
   
            # Now we only have angled good tapes, so we loop through and identify docks
            if len(tape_keeper) != 0:
                 if headless == False: cv2.putText(outimg, "I see " + str(len(tape_keeper)) + " tapes!",(4,110), font, font_size, (255,255,255), 1, cv2.LINE_AA)

                 t = len(tape_keeper)   # t gets the number of pieces of tape.
                 left_side = False      # flag indicating just saw a left (right leaning) piece of tape
                 right_side = False     # flag indicating just saw a right (left leaning) piece of tape
                 target_found = False   # flag indicating we found a left and right pair - a port!
                 target_number = 0      # number of pairs found
                 
                 # Loop through the number of found pairs of tape
                 for ctr in range(t):

                     # If it's a left side, indicate it's point right...
                     if str(tape_keeper[ctr][2]) == "R":
                        left_side = True
                     # If it's a right side, indicate it's pointing left...
                     elif str(tape_keeper[ctr][2]) == "L" and left_side == True:
                        target_found = True
                        target_number = target_number + 1
                        left_side = False
                        right_side = False
                        
                        # Save the center X and center Y for this particular matching pair
                        cx = round(tape_keeper[ctr-1][0][0] + (.5 * (tape_keeper[ctr][0][0]-tape_keeper[ctr-1][0][0])))
                        cy = round(tape_keeper[ctr][0][1])
                        
                        degrees_to_target = (cx - 320) / 9
                        if abs(degrees_to_target) < abs(closest_dock):
                            closest_dock = degrees_to_target
                            closest_dock_cx = cx
                            closest_dock_cy = cy
                        
                        if headless == False: cv2.putText(outimg, "T" + str(target_number),(cx,round(tape_keeper[ctr][0][1])), font, font_size, (255,255,255), 1, cv2.LINE_AA)
                        if headless == False: cv2.putText(outimg, " (" + str(cx) + "," + str(round(tape_keeper[ctr][0][1])) + ")",(cx-30,round(tape_keeper[ctr][0][1])+20), font, font_size, (255,255,255), 1, cv2.LINE_AA)
                        if headless == False: cv2.putText(outimg, str(round(degrees_to_target,1)) +"'",(cx-20,round(tape_keeper[ctr][0][1])+40), font, font_size, (255,255,255), 1, cv2.LINE_AA)
                                    
 
            if headless == False: cv2.putText(outimg, "Team250 Piggy Vision", (3, 20), font, font_size, (255,255,255), 1, cv2.LINE_AA)
            #Focal length in inches is .1102
            #Calculating distance using vertical angle :)
            #vertical_angle = np.rad2deg(np.arctan(abs((cy-240))/251.149))
 
            CAMERA_HEIGHT = 12
            TARGET_HEIGHT = 31.5
            VERTICAL_FOV = 52
            VERTICAL_PXL_PER_DEGREE = 6.75
            HORIZON_Y = 405
            CALIBRATION_FACTOR = 6.3
            
            # Vertical angle is currently 27 degrees
            
            # tx is center of target's x
            # ty is center of target's y
                
            if closest_dock != -99.99:
                if headless == False: cv2.putText(outimg, "Turn -> " + str(round(closest_dock,2)) + " degrees to target", (3, 40), font, font_size, (255,255,255), 1, cv2.LINE_AA)
             
                vertical_angle = ((abs((cy - HORIZON_Y)) / VERTICAL_PXL_PER_DEGREE)/ 2) + 20
                distance = (TARGET_HEIGHT - CAMERA_HEIGHT - CALIBRATION_FACTOR) /((math.tan(math.radians(vertical_angle)))) * 2
                if headless == False: cv2.putText(outimg, "Distance From Target -> " + str(distance), (3, 80), font, font_size, (255,255,255), 1, cv2.LINE_AA)
                if headless == False: cv2.putText(outimg, "Vertical Angle -> " + str(vertical_angle), (3, 95), font, font_size, (255,255,255), 1, cv2.LINE_AA)
                if headless == False: cv2.circle(outimg,(closest_dock_cx,closest_dock_cy),100,(0,255,0),thickness=1,lineType=8,shift=0)
                
                #height, width, channels = outimg.shape # if outimg is grayscale, change to: height, width = outimg.shape
                height, width, channels = outimg.shape
                if headless == False: cv2.putText(outimg, fps, (3, height - 6), font, font_size, (255,255,255), 1, cv2.LINE_AA)

            else:
                if headless == False: cv2.putText(outimg, "*** No target in view! ***", (250, 240), font, font_size, (255,255,255), 1, cv2.LINE_AA)            

            # Convert our BGR output image to video output format and send to host over USB. If your output image is not
            # BGR, you can use sendCvGRAY(), sendCvRGB(), or sendCvRGBA() as appropriate:
        
            outframe.sendCvBGR(outimg)

    
    # ###################################################################################################
    
    # ###################################################################################################

    @staticmethod
    def __blur(src, type, radius):
        """Softens an image using one of several filters.
        Args:
            src: The source mat (numpy.ndarray).
            type: The blurType to perform represented as an int.
            radius: The radius for the blur as a float.
        Returns:
            A numpy.ndarray that has been blurred.
        """
        ksize = int(2 * round(radius) + 1)
        return cv2.blur(src, (ksize, ksize))
                        
    @staticmethod
    def __cv_extractchannel(src, channel):
        """Extracts given channel from an image.
        Args:
            src: A numpy.ndarray.
            channel: Zero indexed channel number to extract.
        Returns:
             The result as a numpy.ndarray.
        """
        return cv2.extractChannel(src, (int) (channel + 0.5))

    @staticmethod
    def __cv_threshold(src, thresh, max_val, type):
        """Apply a fixed-level threshold to each array element in an image
        Args:
            src: A numpy.ndarray.
            thresh: Threshold value.
            max_val: Maximum value for THRES_BINARY and THRES_BINARY_INV.
            type: Opencv enum.
        Returns:
            A black and white numpy.ndarray.
        """
        return cv2.threshold(src, thresh, max_val, type)[1]

    @staticmethod
    def __mask(input, mask):
        """Filter out an area of an image using a binary mask.
        Args:
            input: A three channel numpy.ndarray.
            mask: A black and white numpy.ndarray.
        Returns:
            A three channel numpy.ndarray.
        """
        return cv2.bitwise_and(input, input, mask=mask)

    @staticmethod
    def __normalize(input, type, a, b):
        """Normalizes or remaps the values of pixels in an image.
        Args:
            input: A numpy.ndarray.
            type: Opencv enum.
            a: The minimum value.
            b: The maximum value.
        Returns:
            A numpy.ndarray of the same type as the input.
        """
        return cv2.normalize(input, None, a, b, type)

    @staticmethod
    def __hsv_threshold(input, hue, sat, val):
        """Segment an image based on hue, saturation, and value ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max value.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HSV)
        return cv2.inRange(out, (hue[0], sat[0], val[0]),  (hue[1], sat[1], val[1]))

    @staticmethod
    def __cv_erode(src, kernel, anchor, iterations, border_type, border_value):
        """Expands area of lower value in an image.
        Args:
           src: A numpy.ndarray.
           kernel: The kernel for erosion. A numpy.ndarray.
           iterations: the number of times to erode.
           border_type: Opencv enum that represents a border type.
           border_value: value to be used for a constant border.
        Returns:
            A numpy.ndarray after erosion.
        """
        return cv2.erode(src, kernel, anchor, iterations = (int) (iterations +0.5),
                            borderType = border_type, borderValue = border_value)

    @staticmethod
    def __cv_dilate(src, kernel, anchor, iterations, border_type, border_value):
        """Expands area of higher value in an image.
        Args:
           src: A numpy.ndarray.
           kernel: The kernel for dilation. A numpy.ndarray.
           iterations: the number of times to dilate.
           border_type: Opencv enum that represents a border type.
           border_value: value to be used for a constant border.
        Returns:
            A numpy.ndarray after dilation.
        """
        return cv2.dilate(src, kernel, anchor, iterations = (int) (iterations +0.5),
                            borderType = border_type, borderValue = border_value)

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        #im2, contours, hierarchy = cv2.findContours(input, mode=mode, method=method)
        contours,hierachy=cv2.findContours(input,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
        return contours

    @staticmethod
    def __filter_contours(input_contours, min_area, min_perimeter, min_width, max_width,
                        min_height, max_height, solidity, max_vertex_count, min_vertex_count,
                        min_ratio, max_ratio):
        """Filters out contours that do not meet certain criteria.
        Args:
            input_contours: Contours as a list of numpy.ndarray.
            min_area: The minimum area of a contour that will be kept.
            min_perimeter: The minimum perimeter of a contour that will be kept.
            min_width: Minimum width of a contour.
            max_width: MaxWidth maximum width.
            min_height: Minimum height.
            max_height: Maximimum height.
            solidity: The minimum and maximum solidity of a contour.
            min_vertex_count: Minimum vertex Count of the contours.
            max_vertex_count: Maximum vertex Count.
            min_ratio: Minimum ratio of width to height.
            max_ratio: Maximum ratio of width to height.
        Returns:
            Contours as a list of numpy.ndarray.
        """
        output = []
        for contour in input_contours:
            x,y,w,h = cv2.boundingRect(contour)
            if (w < min_width or w > max_width):
                continue
            if (h < min_height or h > max_height):
                continue
            area = cv2.contourArea(contour)
            if (area < min_area):
                continue
            if (cv2.arcLength(contour, True) < min_perimeter):
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / cv2.contourArea(hull)
            if (solid < solidity[0] or solid > solidity[1]):
                continue
            if (len(contour) < min_vertex_count or len(contour) > max_vertex_count):
                continue
            ratio = (float)(w) / h
            if (ratio < min_ratio or ratio > max_ratio):
                continue
            output.append(contour)
        return output
        
#BlurType = Enum('BlurType', 'Box_Blur Gaussian_Blur Median_Filter Bilateral_Filter')

cv2.destroyAllWindows()    
